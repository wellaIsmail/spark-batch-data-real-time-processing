{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16813f4-814d-4840-8bff-ce200a0ef690",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, regexp_replace, sum, when, sum as spark_sum, avg, rank, desc\n",
    "from pymongo import MongoClient\n",
    "from pyspark.sql.window import Window\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d196cbf2-acc4-4921-9927-ba7c2254a008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b212ba0b-891b-41cd-83a0-2434f97b01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Most popular product categories among different age groups\") \\\n",
    "    .config(\"spark.executor.memory\", \"1g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c9e2ec-a090-4f7b-9eb4-5d4b7f859ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HDFS directories\n",
    "customer_data_dir = \"hdfs://namenode:9000/csv_files/customers/\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d153ae1a-12b8-4de9-a923-8634ba4cd9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- Item_Purchased: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Purchase_Amount_USD: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Color: string (nullable = true)\n",
      " |-- Season: string (nullable = true)\n",
      " |-- Review Rating: string (nullable = true)\n",
      " |-- Subscription Status: string (nullable = true)\n",
      " |-- Shipping Type: string (nullable = true)\n",
      " |-- Discount Applied: string (nullable = true)\n",
      " |-- Promo Code Used: string (nullable = true)\n",
      " |-- Previous Purchases: string (nullable = true)\n",
      " |-- Payment Method: string (nullable = true)\n",
      " |-- Frequency of Purchases: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a static DataFrame to infer the schema for customer data\n",
    "try:\n",
    "    customer_static_df = spark.read \\\n",
    "        .format(\"csv\") \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .load(customer_data_dir)\n",
    "    customer_static_df.printSchema()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error reading static data: {e}\")\n",
    "    spark.stop()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3d6604f-91b6-4454-8350-eeb60a51dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a streaming DataFrame for customer data\n",
    "try:\n",
    "    customer_streaming_df = spark.readStream \\\n",
    "        .schema(customer_static_df.schema) \\\n",
    "        .option(\"header\", \"true\") \\\n",
    "        .csv(customer_data_dir)\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error creating streaming DataFrame: {e}\")\n",
    "    spark.stop()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e153671b-5196-4a5a-b7a4-ccceed0dc52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MongoDB connection setup\n",
    "try:\n",
    "    #client = MongoClient(mongo_host, mongo_port)\n",
    "    client = MongoClient(\"mongodb://mongodb:27017\")\n",
    "    db = client['Products']\n",
    "    coll_popular_categories = db['popular_categories']\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error connecting to MongoDB: {e}\")\n",
    "    spark.stop()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5547f4e5-5cfe-49ae-8a6b-d538a907fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_popular_categories(batch_df, batch_id):\n",
    "   \n",
    "   try:\n",
    "        batch_df = batch_df.withColumn(\"Age_Group\",\n",
    "            when(col(\"age\") < 18, \"Under 18\")\n",
    "            .when((col(\"age\") >= 18) & (col(\"age\") < 30), \"18-29\")\n",
    "            .when((col(\"age\") >= 30) & (col(\"age\") < 40), \"30-39\")\n",
    "            .when((col(\"age\") >= 40) & (col(\"age\") < 50), \"40-49\")\n",
    "            .when((col(\"age\") >= 50) & (col(\"age\") < 60), \"50-59\")\n",
    "            .otherwise(\"60+\"))\n",
    "    \n",
    "    # Group by Age_Group and Category and calculate total purchase amount\n",
    "        category_popularity = batch_df.groupBy(\"Age_Group\", \"Category\").agg(\n",
    "         spark_sum(\"Purchase_Amount_USD\").alias(\"TotalPurchaseAmount\"),\n",
    "         count(\"Item_Purchased\").alias(\"PurchaseCount\")\n",
    "        )\n",
    "    \n",
    "    # Find the most popular categories in each age group by total purchase amount\n",
    "        window_spec = Window.partitionBy(\"Age_Group\").orderBy(col(\"TotalPurchaseAmount\").desc())\n",
    "        popular_categories = category_popularity.withColumn(\"rank\", rank().over(window_spec)).filter(col(\"rank\") == 1)\n",
    "        popular_categories_sorted = popular_categories.orderBy(\"TotalPurchaseAmount\", ascending=False)\n",
    "    \n",
    "    # Convert the DataFrame to a list of dictionaries\n",
    "        popular_categories_list = [row.asDict() for row in popular_categories.collect()]\n",
    "    \n",
    "         # Insert into MongoDB if the list is not empty\n",
    "        if popular_categories_list:\n",
    "          coll_popular_categories.insert_many(popular_categories_list)\n",
    "          popular_categories_sorted.show()\n",
    "          logger.info(f\"Batch {batch_id} processed and inserted into MongoDB\")\n",
    "        else:\n",
    "          logger.info(f\"Batch {batch_id} processed but no high-value customers found\")\n",
    "    # Insert into MongoDB (assuming you have established a connection)\n",
    "    # Replace 'db.high_value_customer_habits' with your MongoDB collection\n",
    "  \n",
    "   except Exception as e:\n",
    "        logger.error(f\"Error processing batch {batch_id}: {e}\")\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4214b-8293-4bea-9e5c-691f6abd9ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:py4j.java_gateway:Callback Server Starting\n",
      "INFO:py4j.java_gateway:Socket listening on ('127.0.0.1', 37639)\n",
      "INFO:py4j.clientserver:Python Server ready to receive messages\n",
      "INFO:py4j.clientserver:Received command c on object id p0\n",
      "ERROR:__main__:Error processing batch 0: name 'insights_list' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Write the streaming DataFrame to the console using the function\n",
    "try:\n",
    "    # Write the streaming DataFrame to the console using the function\n",
    "  query_popular_categories = customer_streaming_df.writeStream \\\n",
    "   .outputMode(\"append\") \\\n",
    "   .foreachBatch(find_popular_categories) \\\n",
    "   .start()\n",
    "    # Await termination\n",
    "  query_popular_categories.awaitTermination()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error in streaming query: {e}\")\n",
    "finally:\n",
    "    # Stop Spark session\n",
    "    spark.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
